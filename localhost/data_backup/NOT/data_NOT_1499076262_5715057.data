id§NOT_1499076262_5715057°datum§07.07.2017°DatumE§2017-07-07-00-00-00_NOT_1499076262_5715057°quelle§persistent°name§mnogosearch Indexer man page / parameter°kategorien§.software.mnogosearch°info§°text§<br/>-----<br/><p>mnogo@dvzmvnma0368:/opt/mnogosearch/mnogosearch-3.3.14&gt; /opt/mnogosearch/mnogosearch-3.3/sbin/indexer s -a -N 1 &nbsp;etc/indexer_rp_sm.conf</p><p>&nbsp;</p><p>indexer from mnogosearch-3.3.14-mysql</p><p>http://www.mnogosearch.org/ (C)1998-2013, LavTech Corp.</p><p>&nbsp;</p><p>Usage: indexer [OPTIONS] &nbsp;[configfile]</p><p>&nbsp;</p><p>Crawler options:</p><p>&nbsp; -a &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Revisit all documents even if not expired (can be</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; limited using -t, -u, -s, -c, -y and -f options)</p><p>&nbsp; -m &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Update expired documents even if not modified (can be</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; limited using -t, -u, -c, -s, -y and -f options)</p><p>&nbsp; -e &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Visit 'most expired' (oldest) documents first</p><p>&nbsp; -o &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Visit documents with less depth (hops value) first</p><p>&nbsp; -r &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Do not try to reduce remote servers load by randomising</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; crawler queue order (faster, but less polite)</p><p>&nbsp; -n # &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Visit only # documents and exit</p><p>&nbsp; -c # &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Visit only # seconds and exit</p><p>&nbsp; -q &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Quick startup (do not add Server URLs); &nbsp;-qq even quicker</p><p>&nbsp; -b &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Block starting more than one indexer instances</p><p>&nbsp; -i &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Insert new URLs (URLs to insert must be given using -u or -f)</p><p>&nbsp; -p # &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Sleep # seconds after downloading every URL</p><p>&nbsp; -w &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Do not ask for confirmation when clearing documents</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; from the database (e.g.: indexer -Cw)</p><p>&nbsp; -N # &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Run # crawler threads</p><p>&nbsp;</p><p>Subsection control options (can be combined):</p><p>&nbsp; -s name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents matching status (HTTP Status code)</p><p>&nbsp; -t name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents matching tag</p><p>&nbsp; -g name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents matching category</p><p>&nbsp; -y name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents matching content-type</p><p>&nbsp; -L name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents matching language</p><p>&nbsp; -u name &nbsp; &nbsp; &nbsp; &nbsp; Limit indexer to documents with URLs matching pattern</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (supports SQL LIKE wildcards '%' and '_')</p><p>&nbsp; --seed=name &nbsp; &nbsp; Limit indexer to documents with the given seed (0-255)</p><p>&nbsp; -D name &nbsp; &nbsp; &nbsp; &nbsp; Work with the n-th database only (i.e. with the n-th DBAddr)</p><p>&nbsp; -f name &nbsp; &nbsp; &nbsp; &nbsp; Read URLs to be visited/inserted/deleted from file (with -a</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; or -C option, supports SQL LIKE wildcard '%%'; has no effect</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; when combined with -m option)</p><p>&nbsp; -f - &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Use stdin instead of a file as an URL list</p><p>&nbsp;</p><p>Logging options:</p><p>&nbsp; -l &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Do not log to stdout/stderr</p><p>&nbsp; -v # &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Verbose level (0-5)</p><p>&nbsp;</p><p>Misc. options:</p><p>&nbsp; -F name &nbsp; &nbsp; &nbsp; &nbsp; Print compile configuration and exit (e.g.: indexer -F '*')</p><p>&nbsp; -h, --help &nbsp; &nbsp; &nbsp;Print help page and exit; -hh print more help</p><p>&nbsp; -? &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Print help page and exit; -?? print more help</p><p>&nbsp; -d name &nbsp; &nbsp; &nbsp; &nbsp; Use the given configuration file instead of indexer.conf</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; This option is usefull when running indexer as an</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; interpreter, e.g.: #!/usr/local/sbin/indexer -d</p><p>&nbsp; -j name &nbsp; &nbsp; &nbsp; &nbsp; Set current time for statistic (use with -S),</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; format: YYYY-MM[-DD[ HH[:MM[:SS]]]]</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; or time offset, e.g. 1d12h (see Period in indexer.conf)</p><p>&nbsp; --set=name &nbsp; &nbsp; &nbsp;Set variable</p><p>&nbsp;</p><p>Commands (can be used with subsection control options):</p><p>&nbsp; --crawl &nbsp; &nbsp; &nbsp; &nbsp; Crawl (default command)</p><p>&nbsp; --index &nbsp; &nbsp; &nbsp; &nbsp; Create search index</p><p>&nbsp; --wordstat &nbsp; &nbsp; &nbsp;Create statistics for misspelled word suggestions</p><p>&nbsp; --rewriteurl &nbsp; &nbsp;Rewrite URL data into the current search index</p><p>&nbsp; --rewritelimits Recreate all Limit, UserScore, UserOrder data</p><p>&nbsp; -C, --delete &nbsp; &nbsp;Delete documents from the database</p><p>&nbsp; -S, --statistics Print statistics and exit</p><p>&nbsp; -I, --referers &nbsp;Print referers and exit</p><p>&nbsp; -R &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Crawl then calculate popularity rank</p><p>&nbsp;</p><p>Other commands:</p><p>&nbsp; --create &nbsp; &nbsp; &nbsp; &nbsp;Create SQL table structure and exit</p><p>&nbsp; --drop &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Drop SQL table structure and exit</p><p>&nbsp; -Q, --sqlmon &nbsp; &nbsp;Run interactive SQL monitor</p><p>&nbsp; --exec=name &nbsp; &nbsp; Execute SQL query</p><p>&nbsp; --checkconf &nbsp; &nbsp; Check configuration file for good syntax</p><p>&nbsp; --hashspell &nbsp; &nbsp; Create hash files for the active Ispell dictionaries</p><p>&nbsp; --dumpspell &nbsp; &nbsp; Dump Ispell data for use with SQLWordForms</p><p>&nbsp; --dumpdata &nbsp; &nbsp; &nbsp;Dump collected data using SQL statements</p><p>&nbsp; --restoredata &nbsp; Load prevously dumped data (give a filename using -f)</p><p>&nbsp;</p>°date§9.10.2015°files§°art§Anleitung